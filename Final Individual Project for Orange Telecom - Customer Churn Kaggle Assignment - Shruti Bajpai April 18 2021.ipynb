{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Customer Churn: InClass Kaggle Competition - Python \n",
    "#### Author Shruti Bajpai\n",
    "\n",
    "This notebook gives an example on the implementation of machine learning pipeline for the InClass Kaggle Competition.\n",
    "\n",
    "Last update on: 19/04/2021\n",
    "Editor/Owner: Shruti Bajpai\n",
    "\n",
    "---\n",
    "\n",
    "The machine learning pipeline includes:\n",
    "\n",
    "1. Data processing \n",
    "- [x] Error correction\n",
    "- [x] Value transformation\n",
    "- [x] Value representation\n",
    "- [x] Variable selection\n",
    "\n",
    "2. Modeling \n",
    "- [x] Machine Learning Models\n",
    "\n",
    "3. Model Implementation  \n",
    "- [x] Obtaining Output to Test Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_std_all_v5\n"
     ]
    }
   ],
   "source": [
    "# Version\n",
    "exp_version = 'v5'  # Experiment version\n",
    "data_prep = 'std'  # full = data transformation, representation, std = standard, only dummy encode\n",
    "var_set = 'all'  # all = all vars, fs = top fisher score, pca = first PCs\n",
    "fname = '_' + data_prep + '_' + var_set + '_' + exp_version  # Name of output file\n",
    "print(fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flag variables to run the data processing steps\n",
    "# Value transformation step\n",
    "enable_trans_cat_dt = False  # Remapping cat variables - Decision tree–based remapping\n",
    "enable_trans_num_dt = False  # Discretizing num variables - Decision tree–based discretization\n",
    "enable_trans_num_ef = False  # Discretizing num variables - Equal frequency discretization\n",
    "enable_trans_num_ew = False  # Discretizing num variables - Equal width discretization\n",
    "# Value representation step\n",
    "enable_repr_dummy = True  # Represent cat variables - Dummy coding\n",
    "enable_repr_icd = False  # Represent cat variables - Incidence (of target variable) replacement\n",
    "enable_repr_woe = False  # Represent cat variables - Weight-of-Evidence (WoE) conversion\n",
    "drop_cat_vars = True  # Drop cat variables after value representation step\n",
    "# Other data processing\n",
    "enable_normalize = True  # Normalize the data to the same range [0, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initiation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data exploration\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Data processing\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OrdinalEncoder, OneHotEncoder, KBinsDiscretizer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.feature_selection import mutual_info_classif, VarianceThreshold\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Modeling\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier, AdaBoostClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import xgboost as xgb\n",
    "\n",
    "# Experimental setup\n",
    "from sklearn.model_selection import KFold, StratifiedKFold, cross_validate, GridSearchCV\n",
    "from imblearn.over_sampling import SMOTE, RandomOverSampler\n",
    "from imblearn.pipeline import Pipeline\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import learning_curve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (a) Read and print out some data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read train, test\n",
    "train = pd.read_csv('orange_churn_train.csv', low_memory=False)\n",
    "test = pd.read_csv('orange_churn_test.csv', low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float64    191\n",
      "object      38\n",
      "int64        3\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cust_id</th>\n",
       "      <th>Var1</th>\n",
       "      <th>Var2</th>\n",
       "      <th>Var3</th>\n",
       "      <th>Var4</th>\n",
       "      <th>Var5</th>\n",
       "      <th>Var6</th>\n",
       "      <th>Var7</th>\n",
       "      <th>Var8</th>\n",
       "      <th>Var9</th>\n",
       "      <th>...</th>\n",
       "      <th>Var222</th>\n",
       "      <th>Var223</th>\n",
       "      <th>Var224</th>\n",
       "      <th>Var225</th>\n",
       "      <th>Var226</th>\n",
       "      <th>Var227</th>\n",
       "      <th>Var228</th>\n",
       "      <th>Var229</th>\n",
       "      <th>Var230</th>\n",
       "      <th>churn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1351.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>catzS2D</td>\n",
       "      <td>LM8l689qOp</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ELof</td>\n",
       "      <td>7P5s</td>\n",
       "      <td>ZI9m</td>\n",
       "      <td>NoEd</td>\n",
       "      <td>mj86</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>644.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>76DJixu</td>\n",
       "      <td>LM8l689qOp</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7P5s</td>\n",
       "      <td>RAYp</td>\n",
       "      <td>F2FyR07IdsN7I</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2583.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>I5dzv5f</td>\n",
       "      <td>LM8l689qOp</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FSa2</td>\n",
       "      <td>RAYp</td>\n",
       "      <td>F2FyR07IdsN7I</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1463.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>xwyAw04</td>\n",
       "      <td>LM8l689qOp</td>\n",
       "      <td>NaN</td>\n",
       "      <td>kG3k</td>\n",
       "      <td>fKCe</td>\n",
       "      <td>RAYp</td>\n",
       "      <td>F2FyR07IdsN7I</td>\n",
       "      <td>mj86</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>77.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>76DJixu</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7P5s</td>\n",
       "      <td>RAYp</td>\n",
       "      <td>F2FyR07IdsN7I</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 232 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   cust_id  Var1  Var2  Var3  Var4  Var5    Var6  Var7  Var8  Var9  ...  \\\n",
       "0        3   NaN   NaN   NaN   NaN   NaN  1351.0   7.0   NaN   NaN  ...   \n",
       "1        4   NaN   NaN   NaN   NaN   NaN   644.0   0.0   NaN   NaN  ...   \n",
       "2        7   NaN   NaN   NaN   NaN   NaN  2583.0   0.0   NaN   NaN  ...   \n",
       "3        8   NaN   NaN   NaN   NaN   NaN  1463.0   7.0   NaN   NaN  ...   \n",
       "4        9   NaN   NaN   NaN   NaN   NaN    77.0   0.0   NaN   NaN  ...   \n",
       "\n",
       "    Var222      Var223  Var224  Var225  Var226  Var227         Var228  Var229  \\\n",
       "0  catzS2D  LM8l689qOp     NaN    ELof    7P5s    ZI9m           NoEd    mj86   \n",
       "1  76DJixu  LM8l689qOp     NaN     NaN    7P5s    RAYp  F2FyR07IdsN7I     NaN   \n",
       "2  I5dzv5f  LM8l689qOp     NaN     NaN    FSa2    RAYp  F2FyR07IdsN7I     NaN   \n",
       "3  xwyAw04  LM8l689qOp     NaN    kG3k    fKCe    RAYp  F2FyR07IdsN7I    mj86   \n",
       "4  76DJixu         NaN     NaN     NaN    7P5s    RAYp  F2FyR07IdsN7I     NaN   \n",
       "\n",
       "   Var230  churn  \n",
       "0     NaN      0  \n",
       "1     NaN      0  \n",
       "2     NaN      1  \n",
       "3     NaN      0  \n",
       "4     NaN      0  \n",
       "\n",
       "[5 rows x 232 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print out to check the data\n",
    "print(train.dtypes.value_counts())\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (b) Create a list of column names to manage variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of numerical and catergorical variables\n",
    "id_var = [\"cust_id\"]  # ID\n",
    "num_vars = train.columns[1:191].tolist()  # First 190 vars\n",
    "cat_vars = train.columns[191:231].tolist()  # Last 40 vars\n",
    "# Target get variable\n",
    "target_var = [\"churn\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (c) Check the target variable class distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "churn\n",
      "0        9264\n",
      "1         736\n",
      "dtype: int64\n",
      "churn\n",
      "0        0.9264\n",
      "1        0.0736\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# By number\n",
    "print(train[target_var].value_counts())\n",
    "# By percentage\n",
    "print(train[target_var].value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Processing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Error, data correction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (a) Check and correct data error - Constant variables\n",
    "\n",
    "Constant variables on train do not contain information and may cause data processing or model training error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drop constant variable: ['Var8', 'Var15', 'Var20', 'Var31', 'Var32', 'Var39', 'Var42', 'Var48', 'Var52', 'Var55', 'Var79', 'Var141', 'Var167', 'Var169', 'Var175', 'Var185', 'Var209', 'Var230']\n"
     ]
    }
   ],
   "source": [
    "# Count number of unique values of each variable\n",
    "vars_nunique = train[num_vars + cat_vars].apply(pd.Series.nunique, dropna=False, axis=0)\n",
    "cont_vars = vars_nunique.index[vars_nunique < 2].tolist()\n",
    "print(\"Drop constant variable:\", cont_vars)\n",
    "# Correct variable list\n",
    "num_vars = [v for v in num_vars if v not in cont_vars]\n",
    "cat_vars = [v for v in cat_vars if v not in cont_vars]\n",
    "# Update train, test\n",
    "train = train[id_var+num_vars+cat_vars+target_var]\n",
    "test = test[id_var+num_vars+cat_vars]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (b) Check and correct data error - Missing values\n",
    "\n",
    "<u>Note:</u>\n",
    "- Always create indicators (dummy variable) to track the missing values imputation.\n",
    "- Since we already filtered out the constant NA vars, the imputor will not drop any vars."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train - # NA of num vars: 1345535\n",
      "Train - # NA of cat vars: 79067\n",
      "Test - # NA of num vars: 1345234\n",
      "Test - # NA of cat vars: 79296\n"
     ]
    }
   ],
   "source": [
    "# Check missing value\n",
    "print('Train - # NA of num vars:', train[num_vars].isna().sum().sum())\n",
    "print('Train - # NA of cat vars:', train[cat_vars].isna().sum().sum())\n",
    "print('Test - # NA of num vars:', test[num_vars].isna().sum().sum())\n",
    "print('Test - # NA of cat vars:', test[cat_vars].isna().sum().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List dummary variables to track missing values imputation\n",
    "na_vars = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numerical variables\n",
    "# Build the missing value imputor using the mean\n",
    "imp = SimpleImputer(missing_values=np.nan, strategy='mean', add_indicator=True)\n",
    "imp.fit(train[num_vars])\n",
    "# Reconstruct the list of vars + indicators\n",
    "na_vars = na_vars + [num_vars[v] + \"_na\" for v in imp.indicator_.features_]\n",
    "impute_vars = num_vars + na_vars\n",
    "# Apply on train, test\n",
    "train[impute_vars] = pd.DataFrame(imp.transform(train[num_vars]), columns=impute_vars)\n",
    "test[impute_vars] = pd.DataFrame(imp.transform(test[num_vars]), columns=impute_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorical variables\n",
    "# Impute missing value using a new category \"Missing\"\n",
    "# Note: If the categorical vars are imputed by most_frequent, the indicators should be added\n",
    "train[cat_vars] = train[cat_vars].fillna('Missing')\n",
    "test[cat_vars] = test[cat_vars].fillna('Missing')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (c) Check and correct data error - Outliers in numerical variables\n",
    "\n",
    "Here, we only check but not impute the outliers.\n",
    "\n",
    "<u>Note:</u>\n",
    "- Before correcting outliers, make sure to understand the nature of the error.\n",
    "- Do not need to correct outliers for missing values indicators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Var1 has # outliers on train, test : 21 [ 0.21 % ] 21 [ 0.21 % ]\n",
      "Var3 has # outliers on train, test : 12 [ 0.12 % ] 3 [ 0.03 % ]\n",
      "Var4 has # outliers on train, test : 2 [ 0.02 % ] 3 [ 0.03 % ]\n",
      "Var5 has # outliers on train, test : 27 [ 0.27 % ] 29 [ 0.29 % ]\n",
      "Var6 has # outliers on train, test : 85 [ 0.85 % ] 85 [ 0.85 % ]\n",
      "Var7 has # outliers on train, test : 214 [ 2.14 % ] 190 [ 1.9 % ]\n",
      "Var9 has # outliers on train, test : 66 [ 0.66 % ] 76 [ 0.76 % ]\n",
      "Var10 has # outliers on train, test : 37 [ 0.37 % ] 32 [ 0.32 % ]\n",
      "Var11 has # outliers on train, test : 18 [ 0.18 % ] 14 [ 0.14 % ]\n",
      "Var12 has # outliers on train, test : 75 [ 0.75 % ] 81 [ 0.81 % ]\n",
      "Var13 has # outliers on train, test : 85 [ 0.85 % ] 72 [ 0.72 % ]\n",
      "Var14 has # outliers on train, test : 14 [ 0.14 % ] 11 [ 0.11 % ]\n",
      "Var16 has # outliers on train, test : 200 [ 2.0 % ] 174 [ 1.74 % ]\n",
      "Var17 has # outliers on train, test : 32 [ 0.32 % ] 37 [ 0.37 % ]\n",
      "Var18 has # outliers on train, test : 12 [ 0.12 % ] 18 [ 0.18 % ]\n",
      "Var19 has # outliers on train, test : 7 [ 0.07 % ] 6 [ 0.06 % ]\n",
      "Var21 has # outliers on train, test : 64 [ 0.64 % ] 67 [ 0.67 % ]\n",
      "Var22 has # outliers on train, test : 65 [ 0.65 % ] 66 [ 0.66 % ]\n",
      "Var23 has # outliers on train, test : 39 [ 0.39 % ] 42 [ 0.42 % ]\n",
      "Var24 has # outliers on train, test : 77 [ 0.77 % ] 97 [ 0.97 % ]\n",
      "Var25 has # outliers on train, test : 78 [ 0.78 % ] 83 [ 0.83 % ]\n",
      "Var26 has # outliers on train, test : 3 [ 0.03 % ] 5 [ 0.05 % ]\n",
      "Var27 has # outliers on train, test : 5 [ 0.05 % ] 6 [ 0.06 % ]\n",
      "Var28 has # outliers on train, test : 131 [ 1.31 % ] 138 [ 1.38 % ]\n",
      "Var29 has # outliers on train, test : 0 [ 0.0 % ] 1 [ 0.01 % ]\n",
      "Var30 has # outliers on train, test : 125 [ 1.25 % ] 141 [ 1.41 % ]\n",
      "Var33 has # outliers on train, test : 113 [ 1.13 % ] 127 [ 1.27 % ]\n",
      "Var34 has # outliers on train, test : 25 [ 0.25 % ] 21 [ 0.21 % ]\n",
      "Var35 has # outliers on train, test : 258 [ 2.58 % ] 320 [ 3.2 % ]\n",
      "Var36 has # outliers on train, test : 43 [ 0.43 % ] 42 [ 0.42 % ]\n",
      "Var37 has # outliers on train, test : 63 [ 0.63 % ] 59 [ 0.59 % ]\n",
      "Var38 has # outliers on train, test : 96 [ 0.96 % ] 116 [ 1.16 % ]\n",
      "Var40 has # outliers on train, test : 33 [ 0.33 % ] 23 [ 0.23 % ]\n",
      "Var41 has # outliers on train, test : 85 [ 0.85 % ] 97 [ 0.97 % ]\n",
      "Var43 has # outliers on train, test : 39 [ 0.39 % ] 29 [ 0.29 % ]\n",
      "Var44 has # outliers on train, test : 138 [ 1.38 % ] 133 [ 1.33 % ]\n",
      "Var45 has # outliers on train, test : 65 [ 0.65 % ] 51 [ 0.51 % ]\n",
      "Var46 has # outliers on train, test : 14 [ 0.14 % ] 15 [ 0.15 % ]\n",
      "Var47 has # outliers on train, test : 9 [ 0.09 % ] 14 [ 0.14 % ]\n",
      "Var49 has # outliers on train, test : 5 [ 0.05 % ] 2 [ 0.02 % ]\n",
      "Var50 has # outliers on train, test : 13 [ 0.13 % ] 14 [ 0.14 % ]\n",
      "Var51 has # outliers on train, test : 108 [ 1.08 % ] 119 [ 1.19 % ]\n",
      "Var53 has # outliers on train, test : 95 [ 0.95 % ] 102 [ 1.02 % ]\n",
      "Var54 has # outliers on train, test : 172 [ 1.72 % ] 153 [ 1.53 % ]\n",
      "Var56 has # outliers on train, test : 118 [ 1.18 % ] 92 [ 0.92 % ]\n",
      "Var58 has # outliers on train, test : 14 [ 0.14 % ] 9 [ 0.09 % ]\n",
      "Var59 has # outliers on train, test : 107 [ 1.07 % ] 98 [ 0.98 % ]\n",
      "Var60 has # outliers on train, test : 39 [ 0.39 % ] 29 [ 0.29 % ]\n",
      "Var61 has # outliers on train, test : 104 [ 1.04 % ] 106 [ 1.06 % ]\n",
      "Var62 has # outliers on train, test : 102 [ 1.02 % ] 109 [ 1.09 % ]\n",
      "Var63 has # outliers on train, test : 76 [ 0.76 % ] 85 [ 0.85 % ]\n",
      "Var64 has # outliers on train, test : 41 [ 0.41 % ] 30 [ 0.3 % ]\n",
      "Var65 has # outliers on train, test : 347 [ 3.47 % ] 313 [ 3.13 % ]\n",
      "Var66 has # outliers on train, test : 66 [ 0.66 % ] 76 [ 0.76 % ]\n",
      "Var67 has # outliers on train, test : 1 [ 0.01 % ] 0 [ 0.0 % ]\n",
      "Var68 has # outliers on train, test : 20 [ 0.2 % ] 19 [ 0.19 % ]\n",
      "Var69 has # outliers on train, test : 237 [ 2.37 % ] 202 [ 2.02 % ]\n",
      "Var70 has # outliers on train, test : 46 [ 0.46 % ] 50 [ 0.5 % ]\n",
      "Var71 has # outliers on train, test : 114 [ 1.14 % ] 99 [ 0.99 % ]\n",
      "Var72 has # outliers on train, test : 184 [ 1.84 % ] 159 [ 1.59 % ]\n",
      "Var73 has # outliers on train, test : 31 [ 0.31 % ] 31 [ 0.31 % ]\n",
      "Var74 has # outliers on train, test : 47 [ 0.47 % ] 31 [ 0.31 % ]\n",
      "Var75 has # outliers on train, test : 140 [ 1.4 % ] 132 [ 1.32 % ]\n",
      "Var76 has # outliers on train, test : 73 [ 0.73 % ] 102 [ 1.02 % ]\n",
      "Var77 has # outliers on train, test : 101 [ 1.01 % ] 118 [ 1.18 % ]\n",
      "Var78 has # outliers on train, test : 235 [ 2.35 % ] 207 [ 2.07 % ]\n",
      "Var80 has # outliers on train, test : 26 [ 0.26 % ] 24 [ 0.24 % ]\n",
      "Var81 has # outliers on train, test : 95 [ 0.95 % ] 97 [ 0.97 % ]\n",
      "Var82 has # outliers on train, test : 174 [ 1.74 % ] 189 [ 1.89 % ]\n",
      "Var83 has # outliers on train, test : 60 [ 0.6 % ] 55 [ 0.55 % ]\n",
      "Var84 has # outliers on train, test : 12 [ 0.12 % ] 10 [ 0.1 % ]\n",
      "Var85 has # outliers on train, test : 95 [ 0.95 % ] 80 [ 0.8 % ]\n",
      "Var86 has # outliers on train, test : 106 [ 1.06 % ] 123 [ 1.23 % ]\n",
      "Var87 has # outliers on train, test : 73 [ 0.73 % ] 77 [ 0.77 % ]\n",
      "Var88 has # outliers on train, test : 23 [ 0.23 % ] 25 [ 0.25 % ]\n",
      "Var89 has # outliers on train, test : 21 [ 0.21 % ] 17 [ 0.17 % ]\n",
      "Var90 has # outliers on train, test : 1 [ 0.01 % ] 0 [ 0.0 % ]\n",
      "Var91 has # outliers on train, test : 114 [ 1.14 % ] 99 [ 0.99 % ]\n",
      "Var92 has # outliers on train, test : 33 [ 0.33 % ] 23 [ 0.23 % ]\n",
      "Var93 has # outliers on train, test : 13 [ 0.13 % ] 19 [ 0.19 % ]\n",
      "Var94 has # outliers on train, test : 166 [ 1.66 % ] 180 [ 1.8 % ]\n",
      "Var95 has # outliers on train, test : 22 [ 0.22 % ] 21 [ 0.21 % ]\n",
      "Var96 has # outliers on train, test : 11 [ 0.11 % ] 14 [ 0.14 % ]\n",
      "Var97 has # outliers on train, test : 27 [ 0.27 % ] 18 [ 0.18 % ]\n",
      "Var98 has # outliers on train, test : 14 [ 0.14 % ] 3 [ 0.03 % ]\n",
      "Var99 has # outliers on train, test : 33 [ 0.33 % ] 42 [ 0.42 % ]\n",
      "Var100 has # outliers on train, test : 12 [ 0.12 % ] 11 [ 0.11 % ]\n",
      "Var101 has # outliers on train, test : 10 [ 0.1 % ] 16 [ 0.16 % ]\n",
      "Var102 has # outliers on train, test : 75 [ 0.75 % ] 70 [ 0.7 % ]\n",
      "Var103 has # outliers on train, test : 29 [ 0.29 % ] 25 [ 0.25 % ]\n",
      "Var104 has # outliers on train, test : 103 [ 1.03 % ] 110 [ 1.1 % ]\n",
      "Var105 has # outliers on train, test : 103 [ 1.03 % ] 110 [ 1.1 % ]\n",
      "Var106 has # outliers on train, test : 22 [ 0.22 % ] 32 [ 0.32 % ]\n",
      "Var107 has # outliers on train, test : 32 [ 0.32 % ] 40 [ 0.4 % ]\n",
      "Var108 has # outliers on train, test : 103 [ 1.03 % ] 109 [ 1.09 % ]\n",
      "Var109 has # outliers on train, test : 85 [ 0.85 % ] 92 [ 0.92 % ]\n",
      "Var110 has # outliers on train, test : 11 [ 0.11 % ] 8 [ 0.08 % ]\n",
      "Var111 has # outliers on train, test : 135 [ 1.35 % ] 116 [ 1.16 % ]\n",
      "Var112 has # outliers on train, test : 68 [ 0.68 % ] 78 [ 0.78 % ]\n",
      "Var113 has # outliers on train, test : 187 [ 1.87 % ] 190 [ 1.9 % ]\n",
      "Var114 has # outliers on train, test : 206 [ 2.06 % ] 176 [ 1.76 % ]\n",
      "Var115 has # outliers on train, test : 108 [ 1.08 % ] 103 [ 1.03 % ]\n",
      "Var116 has # outliers on train, test : 1 [ 0.01 % ] 4 [ 0.04 % ]\n",
      "Var117 has # outliers on train, test : 47 [ 0.47 % ] 43 [ 0.43 % ]\n",
      "Var119 has # outliers on train, test : 83 [ 0.83 % ] 89 [ 0.89 % ]\n",
      "Var120 has # outliers on train, test : 31 [ 0.31 % ] 24 [ 0.24 % ]\n",
      "Var121 has # outliers on train, test : 78 [ 0.78 % ] 90 [ 0.9 % ]\n",
      "Var122 has # outliers on train, test : 1 [ 0.01 % ] 4 [ 0.04 % ]\n",
      "Var123 has # outliers on train, test : 46 [ 0.46 % ] 45 [ 0.45 % ]\n",
      "Var124 has # outliers on train, test : 33 [ 0.33 % ] 30 [ 0.3 % ]\n",
      "Var125 has # outliers on train, test : 47 [ 0.47 % ] 58 [ 0.58 % ]\n",
      "Var126 has # outliers on train, test : 118 [ 1.18 % ] 122 [ 1.22 % ]\n",
      "Var127 has # outliers on train, test : 10 [ 0.1 % ] 16 [ 0.16 % ]\n",
      "Var128 has # outliers on train, test : 23 [ 0.23 % ] 25 [ 0.25 % ]\n",
      "Var129 has # outliers on train, test : 69 [ 0.69 % ] 74 [ 0.74 % ]\n",
      "Var130 has # outliers on train, test : 44 [ 0.44 % ] 32 [ 0.32 % ]\n",
      "Var131 has # outliers on train, test : 3 [ 0.03 % ] 6 [ 0.06 % ]\n",
      "Var132 has # outliers on train, test : 327 [ 3.27 % ] 344 [ 3.44 % ]\n",
      "Var133 has # outliers on train, test : 164 [ 1.64 % ] 186 [ 1.86 % ]\n",
      "Var134 has # outliers on train, test : 231 [ 2.31 % ] 220 [ 2.2 % ]\n",
      "Var135 has # outliers on train, test : 199 [ 1.99 % ] 195 [ 1.95 % ]\n",
      "Var136 has # outliers on train, test : 84 [ 0.84 % ] 100 [ 1.0 % ]\n",
      "Var137 has # outliers on train, test : 10 [ 0.1 % ] 12 [ 0.12 % ]\n",
      "Var138 has # outliers on train, test : 1 [ 0.01 % ] 0 [ 0.0 % ]\n",
      "Var139 has # outliers on train, test : 42 [ 0.42 % ] 46 [ 0.46 % ]\n",
      "Var140 has # outliers on train, test : 178 [ 1.78 % ] 186 [ 1.86 % ]\n",
      "Var142 has # outliers on train, test : 125 [ 1.25 % ] 141 [ 1.41 % ]\n",
      "Var143 has # outliers on train, test : 66 [ 0.66 % ] 93 [ 0.93 % ]\n",
      "Var144 has # outliers on train, test : 223 [ 2.23 % ] 220 [ 2.2 % ]\n",
      "Var145 has # outliers on train, test : 26 [ 0.26 % ] 29 [ 0.29 % ]\n",
      "Var146 has # outliers on train, test : 28 [ 0.28 % ] 12 [ 0.12 % ]\n",
      "Var147 has # outliers on train, test : 160 [ 1.6 % ] 147 [ 1.47 % ]\n",
      "Var148 has # outliers on train, test : 33 [ 0.33 % ] 36 [ 0.36 % ]\n",
      "Var149 has # outliers on train, test : 118 [ 1.18 % ] 129 [ 1.29 % ]\n",
      "Var150 has # outliers on train, test : 44 [ 0.44 % ] 41 [ 0.41 % ]\n",
      "Var151 has # outliers on train, test : 113 [ 1.13 % ] 121 [ 1.21 % ]\n",
      "Var152 has # outliers on train, test : 131 [ 1.31 % ] 138 [ 1.38 % ]\n",
      "Var154 has # outliers on train, test : 102 [ 1.02 % ] 125 [ 1.25 % ]\n",
      "Var155 has # outliers on train, test : 27 [ 0.27 % ] 28 [ 0.28 % ]\n",
      "Var156 has # outliers on train, test : 66 [ 0.66 % ] 76 [ 0.76 % ]\n",
      "Var157 has # outliers on train, test : 140 [ 1.4 % ] 122 [ 1.22 % ]\n",
      "Var158 has # outliers on train, test : 17 [ 0.17 % ] 24 [ 0.24 % ]\n",
      "Var159 has # outliers on train, test : 32 [ 0.32 % ] 30 [ 0.3 % ]\n",
      "Var160 has # outliers on train, test : 69 [ 0.69 % ] 72 [ 0.72 % ]\n",
      "Var161 has # outliers on train, test : 59 [ 0.59 % ] 58 [ 0.58 % ]\n",
      "Var162 has # outliers on train, test : 28 [ 0.28 % ] 15 [ 0.15 % ]\n",
      "Var163 has # outliers on train, test : 209 [ 2.09 % ] 247 [ 2.47 % ]\n",
      "Var164 has # outliers on train, test : 18 [ 0.18 % ] 24 [ 0.24 % ]\n",
      "Var165 has # outliers on train, test : 21 [ 0.21 % ] 15 [ 0.15 % ]\n",
      "Var166 has # outliers on train, test : 32 [ 0.32 % ] 37 [ 0.37 % ]\n",
      "Var168 has # outliers on train, test : 90 [ 0.9 % ] 93 [ 0.93 % ]\n",
      "Var170 has # outliers on train, test : 43 [ 0.43 % ] 32 [ 0.32 % ]\n",
      "Var171 has # outliers on train, test : 130 [ 1.3 % ] 150 [ 1.5 % ]\n",
      "Var172 has # outliers on train, test : 132 [ 1.32 % ] 103 [ 1.03 % ]\n",
      "Var173 has # outliers on train, test : 31 [ 0.31 % ] 37 [ 0.37 % ]\n",
      "Var174 has # outliers on train, test : 34 [ 0.34 % ] 38 [ 0.38 % ]\n",
      "Var176 has # outliers on train, test : 18 [ 0.18 % ] 14 [ 0.14 % ]\n",
      "Var177 has # outliers on train, test : 44 [ 0.44 % ] 30 [ 0.3 % ]\n",
      "Var178 has # outliers on train, test : 57 [ 0.57 % ] 55 [ 0.55 % ]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Var179 has # outliers on train, test : 8 [ 0.08 % ] 10 [ 0.1 % ]\n",
      "Var180 has # outliers on train, test : 109 [ 1.09 % ] 122 [ 1.22 % ]\n",
      "Var181 has # outliers on train, test : 173 [ 1.73 % ] 153 [ 1.53 % ]\n",
      "Var182 has # outliers on train, test : 215 [ 2.15 % ] 238 [ 2.38 % ]\n",
      "Var183 has # outliers on train, test : 31 [ 0.31 % ] 18 [ 0.18 % ]\n",
      "Var184 has # outliers on train, test : 35 [ 0.35 % ] 27 [ 0.27 % ]\n",
      "Var186 has # outliers on train, test : 125 [ 1.25 % ] 141 [ 1.41 % ]\n",
      "Var187 has # outliers on train, test : 56 [ 0.56 % ] 58 [ 0.58 % ]\n",
      "Var188 has # outliers on train, test : 189 [ 1.89 % ] 160 [ 1.6 % ]\n",
      "Var189 has # outliers on train, test : 124 [ 1.24 % ] 137 [ 1.37 % ]\n",
      "Var190 has # outliers on train, test : 40 [ 0.4 % ] 52 [ 0.52 % ]\n"
     ]
    }
   ],
   "source": [
    "# Check the outliers on train, test\n",
    "for v in num_vars:\n",
    "    # Calculate the boundaries on train [mean-3*sd, mean+3*sd]\n",
    "    mu = np.mean(train[v])\n",
    "    sd = np.std(train[v])\n",
    "    lower = mu - 3*sd\n",
    "    upper = mu + 3*sd\n",
    "    # Check outliers using the boundaries\n",
    "    train_out = (train[v] < lower) | (train[v] > upper)\n",
    "    test_out = (test[v] < lower) | (test[v] > upper)\n",
    "    if np.sum(train_out) + np.sum(test_out) > 0:\n",
    "        print(v, \"has # outliers on train, test :\",\n",
    "              np.sum(train_out), \"[\", np.round(100*np.mean(train_out), 2), \"% ]\",\n",
    "              np.sum(test_out), \"[\", np.round(100*np.mean(test_out), 2), \"% ]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (d) Encode categorical variables\n",
    "\n",
    "In Python, most of the machine learning libraries will not handle non-numerical values of categorical varibales (e.g. RF). Therefore, we should encoded the categories using integer values.\n",
    "\n",
    "<u>Note:</u>\n",
    "- Here, the encoder is fitted on both train and test. Therefore, in a few special cases, there are unique categories that appear only on train, or test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode categorical variables as integer values\n",
    "# Note: All the NA values were imputed previously\n",
    "enc = OrdinalEncoder()\n",
    "enc.fit(pd.concat([train[cat_vars], test[cat_vars]], axis=0))\n",
    "# Apply on train, test\n",
    "train[cat_vars] = enc.transform(train[cat_vars])\n",
    "test[cat_vars] = enc.transform(test[cat_vars])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (e) Finalize the processed data\n",
    "\n",
    "Current lists of variables:\n",
    "- id_var : customer ID\n",
    "- num_vars : numerical variables\n",
    "- cat_vars : categorical variables\n",
    "- na_vars : indicators for tracking missing values, bool [False, True]\n",
    "- target_var : target variable, churn [0, 1]\n",
    "\n",
    "<u>Note:</u> If there are any variables exist in only train or test, drop them from all the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert bool variable to int\n",
    "train[na_vars] = train[na_vars].astype(np.int8)\n",
    "test[na_vars] = test[na_vars].astype(np.int8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# id_var [ 1 ] : ['cust_id']\n",
      "# num_vars [ 174 ] : ['Var1', 'Var2', 'Var3', 'Var4', 'Var5'] ...\n",
      "# cat_vars [ 38 ] : ['Var191', 'Var192', 'Var193', 'Var194', 'Var195'] ...\n",
      "# na_vars [ 171 ] : ['Var1_na', 'Var2_na', 'Var3_na', 'Var4_na', 'Var5_na'] ...\n",
      "# target_var [ 1 ] : ['churn']\n"
     ]
    }
   ],
   "source": [
    "# Print out the final variables\n",
    "print(\"# id_var [\", len(id_var), \"] :\", id_var)\n",
    "print(\"# num_vars [\", len(num_vars), \"] :\", num_vars[:5], \"...\")\n",
    "print(\"# cat_vars [\", len(cat_vars), \"] :\", cat_vars[:5], \"...\")\n",
    "print(\"# na_vars [\", len(na_vars), \"] :\", na_vars[:5], \"...\")\n",
    "print(\"# target_var [\", len(target_var), \"] :\", target_var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 385)\n",
      "(10000, 384)\n"
     ]
    }
   ],
   "source": [
    "# Sort the data according to the variables list\n",
    "train = train[id_var + num_vars + cat_vars + na_vars + target_var]\n",
    "test = test[id_var + num_vars + cat_vars + na_vars]\n",
    "print(train.shape)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Feature engineering\n",
    "\n",
    "Since every variables are anonymized, we cannot create new variables based the meaning of current variables.\n",
    "\n",
    "In other case, we can use the following hints:\n",
    "- Quickly check the potentially important variables.\n",
    "- Focus on the most important variables to create new variables.\n",
    "- Create a cross variable framework (e.g. customer activities, date-time, events, etc.) for searching the new variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (a) Quickly detect most (potentially) important varriables - Correlation test for numerical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 vars [+] correlated with target var :\n",
      "Var113    0.054660\n",
      "Var131    0.033685\n",
      "Var126    0.030609\n",
      "Var173    0.029983\n",
      "Var81     0.028262\n",
      "Name: churn, dtype: float64\n",
      "Top 5 vars [-] correlated with target var :\n",
      "Var189   -0.087654\n",
      "Var73    -0.073407\n",
      "Var7     -0.059302\n",
      "Var65    -0.047361\n",
      "Var13    -0.039086\n",
      "Name: churn, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Pearson's correlation for numerical variables\n",
    "corr = train[num_vars + target_var].corr(method='pearson')\n",
    "corr = corr['churn'][:-1].dropna()\n",
    "print(\"Top 5 vars [+] correlated with target var :\"); print(corr.sort_values(ascending=False)[:5])\n",
    "print(\"Top 5 vars [-] correlated with target var :\"); print(corr.sort_values(ascending=True)[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (b) Quickly detect most (potentially) important varriables - Mutual information\n",
    "\n",
    "<u>Reference:</u>\n",
    "- Mutual information. Link: https://en.wikipedia.org/wiki/Mutual_information\n",
    "- sklearn.feature_selection.mutual_info_classif. Link: https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.mutual_info_classif.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 vars :\n",
      "Var193    0.009399\n",
      "Var210    0.008983\n",
      "Var217    0.007949\n",
      "Var205    0.006955\n",
      "Var218    0.006935\n",
      "Var221    0.006823\n",
      "Var212    0.006762\n",
      "Var202    0.005104\n",
      "Var192    0.005007\n",
      "Var208    0.004731\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Check mutual information for all variables\n",
    "# Note: The calculation involves a random process, therefore, the result may change if there is no\n",
    "# variable with significant information.\n",
    "mutual_info = mutual_info_classif(train[cat_vars], train[target_var].values.squeeze())\n",
    "mutual_info = pd.Series(mutual_info, index=cat_vars)\n",
    "print(\"Top 10 vars :\"); print(mutual_info.sort_values(ascending=False)[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  (a) Variable selection: Fisher Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create several lists to handle variables\n",
    "id_var = ['cust_id']\n",
    "target_var = ['churn']\n",
    "predictors = [v for v in train.columns if v not in id_var + target_var]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FisherScore(bt, target_var, predictors):\n",
    "    \"\"\"\n",
    "    This function calculate the Fisher score of a variable.\n",
    "\n",
    "    Ref:\n",
    "    ---\n",
    "    Verbeke, W., Dejaeger, K., Martens, D., Hur, J., & Baesens, B. (2012). New insights\n",
    "    into churn prediction in the telecommunication sector: A profit driven data mining\n",
    "    approach. European Journal of Operational Research, 218(1), 211-229.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Get the unique values of dependent variable\n",
    "    target_var_val = bt[target_var].unique()\n",
    "    # Calculate FisherScore for each predictor\n",
    "    predictor_FisherScore = []\n",
    "    for v in predictors:\n",
    "        fs = np.abs(np.mean(bt.loc[bt[target_var]==target_var_val[0], v]) - np.mean(bt.loc[bt[target_var]==target_var_val[1], v])) / \\\n",
    "             np.sqrt(np.var(bt.loc[bt[target_var]==target_var_val[0], v]) + np.var(bt.loc[bt[target_var]==target_var_val[1], v]))\n",
    "        predictor_FisherScore.append(fs)\n",
    "    return predictor_FisherScore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-27-0c2aaa030081>:17: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  fs = np.abs(np.mean(bt.loc[bt[target_var]==target_var_val[0], v]) - np.mean(bt.loc[bt[target_var]==target_var_val[1], v])) / \\\n",
      "<ipython-input-27-0c2aaa030081>:17: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  fs = np.abs(np.mean(bt.loc[bt[target_var]==target_var_val[0], v]) - np.mean(bt.loc[bt[target_var]==target_var_val[1], v])) / \\\n",
      "<ipython-input-27-0c2aaa030081>:17: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  fs = np.abs(np.mean(bt.loc[bt[target_var]==target_var_val[0], v]) - np.mean(bt.loc[bt[target_var]==target_var_val[1], v])) / \\\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predictor</th>\n",
       "      <th>fisherscore</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>323</th>\n",
       "      <td>Var126_na</td>\n",
       "      <td>0.271197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>Var189</td>\n",
       "      <td>0.230800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>Var73</td>\n",
       "      <td>0.217568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>Var218</td>\n",
       "      <td>0.196487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Var7</td>\n",
       "      <td>0.164765</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     predictor  fisherscore\n",
       "323  Var126_na     0.271197\n",
       "172     Var189     0.230800\n",
       "62       Var73     0.217568\n",
       "200     Var218     0.196487\n",
       "6         Var7     0.164765"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate Fisher Score for all variable\n",
    "fs = FisherScore(train, target_var[0], predictors)\n",
    "fs_df = pd.DataFrame({\"predictor\":predictors, \"fisherscore\":fs})\n",
    "fs_df = fs_df.sort_values('fisherscore', ascending=False)\n",
    "fs_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize the Fisher Score\n",
    "plt.plot(fs_df['fisherscore'].values.squeeze())\n",
    "plt.axhline(y=0.01, linestyle='dashed', color='red')\n",
    "plt.axhline(y=0.03, linestyle='dashed', color='green')\n",
    "plt.xticks(rotation=45)\n",
    "plt.xlabel(str(fs_df.shape[0]) + ' predictors')\n",
    "plt.ylabel('Fisher Score')\n",
    "plt.legend(['Fisher Score', '0.01', '0.03'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected # vars : 50\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['Var126_na', 'Var189', 'Var73', 'Var218', 'Var7', 'Var113',\n",
       "       'Var207', 'Var65', 'Var13', 'Var193', 'Var144', 'Var229', 'Var210',\n",
       "       'Var220', 'Var126', 'Var205', 'Var140', 'Var228', 'Var81',\n",
       "       'Var125', 'Var74', 'Var195', 'Var72', 'Var6', 'Var134',\n",
       "       'Var118_na', 'Var92_na', 'Var197', 'Var28', 'Var200', 'Var194',\n",
       "       'Var201', 'Var147', 'Var221', 'Var119', 'Var109', 'Var112',\n",
       "       'Var51', 'Var173', 'Var77', 'Var203', 'Var211', 'Var160', 'Var37',\n",
       "       'Var132', 'Var24', 'Var222', 'Var81_na', 'Var144_na', 'Var6_na'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Select the top variables based on Fisher Score\n",
    "# top_fs_vars = fs_df[fs_df['fisherscore'] >= 0.03]['predictor'].values\n",
    "top_fs_vars = fs_df['predictor'].values[:50]\n",
    "print(\"Selected # vars :\", len(top_fs_vars))\n",
    "top_fs_vars"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (b) Dimensional Reduction: PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PVE = 0.9999999999945487\n"
     ]
    }
   ],
   "source": [
    "# Build PCA and check the explained variance\n",
    "# Note: If the num vars were scaled (but the dummy were not) PVE is no longer correct\n",
    "pca = PCA(n_components=100)\n",
    "pca.fit(train[predictors])\n",
    "print(\"PVE =\", pca.explained_variance_ratio_.sum())\n",
    "# Transform train, test\n",
    "train_pca = pca.transform(train[predictors])\n",
    "test_pca = pca.transform(test[predictors])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize the PVE of PCA\n",
    "plt.plot(np.cumsum(pca.explained_variance_ratio_))\n",
    "plt.xlabel('PC')\n",
    "plt.ylabel('PVE')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basetable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pca_df = pd.DataFrame(train_pca)\n",
    "test_pca_df = pd.DataFrame(test_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>90</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.120921e+06</td>\n",
       "      <td>1382.926563</td>\n",
       "      <td>2.618250e+05</td>\n",
       "      <td>6.033320e+05</td>\n",
       "      <td>-5.149695e+05</td>\n",
       "      <td>-6637.074611</td>\n",
       "      <td>-7.528463e+04</td>\n",
       "      <td>385215.727461</td>\n",
       "      <td>55236.920600</td>\n",
       "      <td>-144.246584</td>\n",
       "      <td>...</td>\n",
       "      <td>-4.197877</td>\n",
       "      <td>-0.809334</td>\n",
       "      <td>5.247311</td>\n",
       "      <td>-1.769750</td>\n",
       "      <td>-6.093992</td>\n",
       "      <td>1.623660</td>\n",
       "      <td>0.170005</td>\n",
       "      <td>6.351277</td>\n",
       "      <td>0.614337</td>\n",
       "      <td>4.847624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.208672e+06</td>\n",
       "      <td>1126.443975</td>\n",
       "      <td>-1.615208e+06</td>\n",
       "      <td>-8.799284e+05</td>\n",
       "      <td>-6.591156e+05</td>\n",
       "      <td>-37307.011877</td>\n",
       "      <td>-4.190200e+05</td>\n",
       "      <td>-190482.880666</td>\n",
       "      <td>143341.238830</td>\n",
       "      <td>-1816.791105</td>\n",
       "      <td>...</td>\n",
       "      <td>2.923935</td>\n",
       "      <td>1.858305</td>\n",
       "      <td>20.208964</td>\n",
       "      <td>2.960141</td>\n",
       "      <td>4.557753</td>\n",
       "      <td>-1.202465</td>\n",
       "      <td>-0.806956</td>\n",
       "      <td>-18.726068</td>\n",
       "      <td>-1.345178</td>\n",
       "      <td>-11.643057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9.419038e+05</td>\n",
       "      <td>537.525459</td>\n",
       "      <td>-1.332966e+06</td>\n",
       "      <td>-5.601405e+05</td>\n",
       "      <td>1.531879e+06</td>\n",
       "      <td>-13119.961209</td>\n",
       "      <td>-1.348529e+05</td>\n",
       "      <td>-704117.095401</td>\n",
       "      <td>153799.187888</td>\n",
       "      <td>-787.823424</td>\n",
       "      <td>...</td>\n",
       "      <td>3.403000</td>\n",
       "      <td>0.708272</td>\n",
       "      <td>4.871062</td>\n",
       "      <td>-2.005455</td>\n",
       "      <td>-8.675416</td>\n",
       "      <td>2.512780</td>\n",
       "      <td>0.090229</td>\n",
       "      <td>-0.006291</td>\n",
       "      <td>0.677992</td>\n",
       "      <td>4.256737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-2.333822e+06</td>\n",
       "      <td>-1074.781947</td>\n",
       "      <td>-1.369667e+06</td>\n",
       "      <td>3.449439e+05</td>\n",
       "      <td>1.832196e+06</td>\n",
       "      <td>13228.576349</td>\n",
       "      <td>1.522140e+05</td>\n",
       "      <td>195109.117998</td>\n",
       "      <td>-367104.593475</td>\n",
       "      <td>670.095719</td>\n",
       "      <td>...</td>\n",
       "      <td>5.922022</td>\n",
       "      <td>0.571973</td>\n",
       "      <td>4.785329</td>\n",
       "      <td>-1.092374</td>\n",
       "      <td>-5.517926</td>\n",
       "      <td>1.056064</td>\n",
       "      <td>0.066631</td>\n",
       "      <td>4.535946</td>\n",
       "      <td>0.941230</td>\n",
       "      <td>4.744873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.174109e+06</td>\n",
       "      <td>798.582080</td>\n",
       "      <td>4.588345e+05</td>\n",
       "      <td>4.712176e+06</td>\n",
       "      <td>1.362118e+06</td>\n",
       "      <td>-8922.338713</td>\n",
       "      <td>-6.740531e+04</td>\n",
       "      <td>573973.508708</td>\n",
       "      <td>44521.147589</td>\n",
       "      <td>146.516082</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.822054</td>\n",
       "      <td>0.429935</td>\n",
       "      <td>6.802518</td>\n",
       "      <td>-0.438395</td>\n",
       "      <td>-0.844239</td>\n",
       "      <td>0.293897</td>\n",
       "      <td>-0.293586</td>\n",
       "      <td>2.224526</td>\n",
       "      <td>-0.218235</td>\n",
       "      <td>0.173227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>-7.046638e+06</td>\n",
       "      <td>-1853.091286</td>\n",
       "      <td>4.177761e+05</td>\n",
       "      <td>-3.247449e+05</td>\n",
       "      <td>-1.555218e+05</td>\n",
       "      <td>-17973.521973</td>\n",
       "      <td>-2.043957e+05</td>\n",
       "      <td>-29937.059424</td>\n",
       "      <td>105298.418646</td>\n",
       "      <td>-877.460732</td>\n",
       "      <td>...</td>\n",
       "      <td>-4.392665</td>\n",
       "      <td>-0.315855</td>\n",
       "      <td>-0.905852</td>\n",
       "      <td>2.618980</td>\n",
       "      <td>13.854976</td>\n",
       "      <td>-3.151031</td>\n",
       "      <td>-0.487023</td>\n",
       "      <td>-3.305908</td>\n",
       "      <td>-0.154423</td>\n",
       "      <td>1.513349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>-5.897648e+06</td>\n",
       "      <td>-1106.707416</td>\n",
       "      <td>-1.568983e+05</td>\n",
       "      <td>-2.670548e+05</td>\n",
       "      <td>2.384702e+05</td>\n",
       "      <td>-39808.698040</td>\n",
       "      <td>-4.428090e+05</td>\n",
       "      <td>-147602.218538</td>\n",
       "      <td>64090.314445</td>\n",
       "      <td>-1909.415017</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.828710</td>\n",
       "      <td>0.155877</td>\n",
       "      <td>6.892568</td>\n",
       "      <td>0.093047</td>\n",
       "      <td>-0.810010</td>\n",
       "      <td>0.492026</td>\n",
       "      <td>0.312018</td>\n",
       "      <td>19.120845</td>\n",
       "      <td>-0.916041</td>\n",
       "      <td>-8.871794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>-3.191363e+06</td>\n",
       "      <td>-1731.729132</td>\n",
       "      <td>-1.795086e+05</td>\n",
       "      <td>7.118814e+05</td>\n",
       "      <td>3.769904e+05</td>\n",
       "      <td>36113.725863</td>\n",
       "      <td>4.069311e+05</td>\n",
       "      <td>-47091.126869</td>\n",
       "      <td>-144291.677140</td>\n",
       "      <td>1671.885244</td>\n",
       "      <td>...</td>\n",
       "      <td>-4.081403</td>\n",
       "      <td>0.682411</td>\n",
       "      <td>8.017443</td>\n",
       "      <td>-1.677489</td>\n",
       "      <td>-5.731592</td>\n",
       "      <td>1.734728</td>\n",
       "      <td>0.166540</td>\n",
       "      <td>3.875549</td>\n",
       "      <td>-0.178679</td>\n",
       "      <td>-2.516850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>-7.606501e+04</td>\n",
       "      <td>2796.343902</td>\n",
       "      <td>1.128226e+04</td>\n",
       "      <td>-5.508521e+04</td>\n",
       "      <td>-1.937103e+04</td>\n",
       "      <td>-152240.402074</td>\n",
       "      <td>-1.689305e+06</td>\n",
       "      <td>-54123.953771</td>\n",
       "      <td>-5642.505321</td>\n",
       "      <td>211486.051989</td>\n",
       "      <td>...</td>\n",
       "      <td>3.211039</td>\n",
       "      <td>-157.548728</td>\n",
       "      <td>1.509314</td>\n",
       "      <td>0.564259</td>\n",
       "      <td>2.022103</td>\n",
       "      <td>-0.396009</td>\n",
       "      <td>-0.571295</td>\n",
       "      <td>-2.258200</td>\n",
       "      <td>0.150928</td>\n",
       "      <td>4.205040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>3.943636e+06</td>\n",
       "      <td>1276.158378</td>\n",
       "      <td>-7.203531e+05</td>\n",
       "      <td>-6.167309e+05</td>\n",
       "      <td>-1.072706e+05</td>\n",
       "      <td>255.069292</td>\n",
       "      <td>2.283746e+03</td>\n",
       "      <td>-211237.187027</td>\n",
       "      <td>144256.060277</td>\n",
       "      <td>-47.626960</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.104121</td>\n",
       "      <td>-0.271058</td>\n",
       "      <td>-6.514567</td>\n",
       "      <td>2.157453</td>\n",
       "      <td>8.334829</td>\n",
       "      <td>-1.911271</td>\n",
       "      <td>0.189170</td>\n",
       "      <td>5.427638</td>\n",
       "      <td>1.644742</td>\n",
       "      <td>16.931144</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                0            1             2             3             4   \\\n",
       "0     4.120921e+06  1382.926563  2.618250e+05  6.033320e+05 -5.149695e+05   \n",
       "1     1.208672e+06  1126.443975 -1.615208e+06 -8.799284e+05 -6.591156e+05   \n",
       "2     9.419038e+05   537.525459 -1.332966e+06 -5.601405e+05  1.531879e+06   \n",
       "3    -2.333822e+06 -1074.781947 -1.369667e+06  3.449439e+05  1.832196e+06   \n",
       "4     3.174109e+06   798.582080  4.588345e+05  4.712176e+06  1.362118e+06   \n",
       "...            ...          ...           ...           ...           ...   \n",
       "9995 -7.046638e+06 -1853.091286  4.177761e+05 -3.247449e+05 -1.555218e+05   \n",
       "9996 -5.897648e+06 -1106.707416 -1.568983e+05 -2.670548e+05  2.384702e+05   \n",
       "9997 -3.191363e+06 -1731.729132 -1.795086e+05  7.118814e+05  3.769904e+05   \n",
       "9998 -7.606501e+04  2796.343902  1.128226e+04 -5.508521e+04 -1.937103e+04   \n",
       "9999  3.943636e+06  1276.158378 -7.203531e+05 -6.167309e+05 -1.072706e+05   \n",
       "\n",
       "                 5             6              7              8   \\\n",
       "0      -6637.074611 -7.528463e+04  385215.727461   55236.920600   \n",
       "1     -37307.011877 -4.190200e+05 -190482.880666  143341.238830   \n",
       "2     -13119.961209 -1.348529e+05 -704117.095401  153799.187888   \n",
       "3      13228.576349  1.522140e+05  195109.117998 -367104.593475   \n",
       "4      -8922.338713 -6.740531e+04  573973.508708   44521.147589   \n",
       "...             ...           ...            ...            ...   \n",
       "9995  -17973.521973 -2.043957e+05  -29937.059424  105298.418646   \n",
       "9996  -39808.698040 -4.428090e+05 -147602.218538   64090.314445   \n",
       "9997   36113.725863  4.069311e+05  -47091.126869 -144291.677140   \n",
       "9998 -152240.402074 -1.689305e+06  -54123.953771   -5642.505321   \n",
       "9999     255.069292  2.283746e+03 -211237.187027  144256.060277   \n",
       "\n",
       "                 9   ...        90          91         92        93  \\\n",
       "0       -144.246584  ... -4.197877   -0.809334   5.247311 -1.769750   \n",
       "1      -1816.791105  ...  2.923935    1.858305  20.208964  2.960141   \n",
       "2       -787.823424  ...  3.403000    0.708272   4.871062 -2.005455   \n",
       "3        670.095719  ...  5.922022    0.571973   4.785329 -1.092374   \n",
       "4        146.516082  ... -2.822054    0.429935   6.802518 -0.438395   \n",
       "...             ...  ...       ...         ...        ...       ...   \n",
       "9995    -877.460732  ... -4.392665   -0.315855  -0.905852  2.618980   \n",
       "9996   -1909.415017  ... -3.828710    0.155877   6.892568  0.093047   \n",
       "9997    1671.885244  ... -4.081403    0.682411   8.017443 -1.677489   \n",
       "9998  211486.051989  ...  3.211039 -157.548728   1.509314  0.564259   \n",
       "9999     -47.626960  ... -1.104121   -0.271058  -6.514567  2.157453   \n",
       "\n",
       "             94        95        96         97        98         99  \n",
       "0     -6.093992  1.623660  0.170005   6.351277  0.614337   4.847624  \n",
       "1      4.557753 -1.202465 -0.806956 -18.726068 -1.345178 -11.643057  \n",
       "2     -8.675416  2.512780  0.090229  -0.006291  0.677992   4.256737  \n",
       "3     -5.517926  1.056064  0.066631   4.535946  0.941230   4.744873  \n",
       "4     -0.844239  0.293897 -0.293586   2.224526 -0.218235   0.173227  \n",
       "...         ...       ...       ...        ...       ...        ...  \n",
       "9995  13.854976 -3.151031 -0.487023  -3.305908 -0.154423   1.513349  \n",
       "9996  -0.810010  0.492026  0.312018  19.120845 -0.916041  -8.871794  \n",
       "9997  -5.731592  1.734728  0.166540   3.875549 -0.178679  -2.516850  \n",
       "9998   2.022103 -0.396009 -0.571295  -2.258200  0.150928   4.205040  \n",
       "9999   8.334829 -1.911271  0.189170   5.427638  1.644742  16.931144  \n",
       "\n",
       "[10000 rows x 100 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Basetable\n",
    "train_pca_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "basetable = train_pca_df.to_csv(r'C:\\Users\\bajpa\\Desktop\\IESEG\\Stastical and Machine Learning Approaches\\Individual Project\\Final Individual Project Folder\\shruti_basetable_kaggle.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Modeling\n",
    "\n",
    "<u>Reference:</u>  \n",
    "\n",
    "- Lessmann, S., Baesens, B., Seow, H. V., & Thomas, L. C. (2015). Benchmarking state-of-the-art classification algorithms for credit scoring: An update of research. European Journal of Operational Research, 247(1), 124-136.File "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pandas               as pd\n",
    "import numpy                as np\n",
    "import seaborn              as sns\n",
    "import matplotlib.pyplot    as plt\n",
    "from pandas                 import DataFrame\n",
    "from pandas                 import read_csv\n",
    "from pandas                 import Series\n",
    "from numpy                  import array\n",
    "from numpy                  import random\n",
    "from matplotlib             import pyplot\n",
    "import warnings\n",
    "from pandas               import get_dummies\n",
    "from numpy                import where\n",
    "from numpy                import nan\n",
    "from scipy.stats.mstats   import winsorize\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from scipy.stats.mstats import winsorize\n",
    "from scipy.stats          import pearsonr\n",
    "import warnings\n",
    "from sklearn import linear_model\n",
    "from sklearn.linear_model   import LogisticRegression\n",
    "from sklearn.tree           import DecisionTreeClassifier\n",
    "from sklearn.ensemble       import RandomForestClassifier\n",
    "from sklearn.ensemble       import GradientBoostingClassifier\n",
    "from sklearn.svm            import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors      import KNeighborsClassifier\n",
    "from sklearn.metrics        import auc\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics        import accuracy_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics        import auc\n",
    "from sklearn.metrics        import roc_auc_score\n",
    "from sklearn.metrics        import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 100)"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_pca.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "x_train = scaler.fit_transform(x_train)\n",
    "x_test = scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test=train_test_split(train_pca,train['churn'],test_size = 0.2, random_state = 123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instanciating the Models\n",
    "\n",
    "tree         = DecisionTreeClassifier()\n",
    "logistic     = LogisticRegression(solver = \"lbfgs\", max_iter = 500)\n",
    "randomForest = RandomForestClassifier(n_estimators = 100)\n",
    "boostedTree  = GradientBoostingClassifier()\n",
    "svm          = SVC(gamma = \"scale\", probability = True)\n",
    "neuralNet    = MLPClassifier()\n",
    "neighbors    = KNeighborsClassifier() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Gaussian Naive Bayes model\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "#Create a Gaussian Classifier\n",
    "gnb = GaussianNB()\n",
    "\n",
    "#Train the model using the training sets\n",
    "gnb.fit(x_train, y_train)\n",
    "\n",
    "#Predict the response for test dataset\n",
    "y_pred = gnb.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Make prediction\n",
    "\n",
    "Use the best model to make prediction on test set. Submit the result to Kaggle."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0.53507 nearest neighbors score for kaggle 8 submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(x_train)\n",
    "\n",
    "x_train = scaler.transform(x_train)\n",
    "x_test = scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier()"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "classifier = KNeighborsClassifier(n_neighbors=5)\n",
    "classifier.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_neighbors = classifier.predict(test_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictionproba_neighbors = neighbors.predict_proba(test_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       0.4\n",
      "1       0.0\n",
      "2       0.0\n",
      "3       0.0\n",
      "4       0.2\n",
      "       ... \n",
      "9995    0.2\n",
      "9996    0.0\n",
      "9997    0.2\n",
      "9998    0.0\n",
      "9999    0.2\n",
      "Name: 1, Length: 10000, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "result_neighbors = pd.DataFrame(predictionproba_neighbors)\n",
    "print(result_neighbors[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['prediction'] = result_neighbors[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_result_neighbors = test[['cust_id','prediction']]\n",
    "export_result_neighbors.to_csv(r\"C:\\Users\\bajpa\\Desktop\\IESEG\\Stastical and Machine Learning Approaches\\Individual Project\\kaggle8.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0.52327 score for kaggle 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier()"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_tree = tree.predict(test_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictionproba_tree = tree.predict_proba(test_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       0.0\n",
      "1       0.0\n",
      "2       0.0\n",
      "3       0.0\n",
      "4       1.0\n",
      "       ... \n",
      "9995    1.0\n",
      "9996    0.0\n",
      "9997    0.0\n",
      "9998    0.0\n",
      "9999    0.0\n",
      "Name: 1, Length: 10000, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "result_tree = pd.DataFrame(predictionproba_tree)\n",
    "print(result_tree[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['prediction'] = result_tree[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_result_result_tree = test[['cust_id','prediction']]\n",
    "export_result_result_tree.to_csv(r\"C:\\Users\\bajpa\\Desktop\\IESEG\\Stastical and Machine Learning Approaches\\Individual Project\\kaggle7.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier()"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neuralNet.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_neuralNet = neuralNet.predict(test_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictionproba_neuralNet = neuralNet.predict_proba(test_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       2.402785e-02\n",
      "1       4.480473e-04\n",
      "2       2.435504e-03\n",
      "3       7.013080e-02\n",
      "4       3.298309e-03\n",
      "            ...     \n",
      "9995    4.675560e-02\n",
      "9996    4.551238e-10\n",
      "9997    4.210335e-01\n",
      "9998    7.892970e-05\n",
      "9999    6.673683e-04\n",
      "Name: 1, Length: 10000, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "result_neuralNet = pd.DataFrame(predictionproba_neuralNet)\n",
    "print(result_neuralNet[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['prediction'] = result_neuralNet[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_result_neuralNet = test[['cust_id','prediction']]\n",
    "export_result_neuralNet.to_csv(r\"C:\\Users\\bajpa\\Desktop\\IESEG\\Stastical and Machine Learning Approaches\\Individual Project\\kaggle6.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#random forest 0.58371 kaggle 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "randomForest.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_randomForest = randomForest.predict(test_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictionproba_randomForest = randomForest.predict_proba(test_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       0.05\n",
      "1       0.04\n",
      "2       0.01\n",
      "3       0.16\n",
      "4       0.13\n",
      "        ... \n",
      "9995    0.07\n",
      "9996    0.10\n",
      "9997    0.07\n",
      "9998    0.01\n",
      "9999    0.07\n",
      "Name: 1, Length: 10000, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "result_randomForest = pd.DataFrame(predictionproba_randomForest)\n",
    "print(result_randomForest[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['prediction'] = result_randomForest[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_result_randomForest = test[['cust_id','prediction']]\n",
    "export_result_randomForest.to_csv(r\"C:\\Users\\bajpa\\Desktop\\IESEG\\Stastical and Machine Learning Approaches\\Individual Project\\kaggle5.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#0.65556 Logistic regression submission kaggle 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg = LogisticRegression()\n",
    "logreg.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_logistic = logreg.predict(test_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictionproba_logistic = logreg.predict_proba(test_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       0.131396\n",
      "1       0.071057\n",
      "2       0.073368\n",
      "3       0.110457\n",
      "4       0.125005\n",
      "          ...   \n",
      "9995    0.128260\n",
      "9996    0.003006\n",
      "9997    0.125729\n",
      "9998    0.043923\n",
      "9999    0.079804\n",
      "Name: 1, Length: 10000, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "result_logistic = pd.DataFrame(predictionproba_logistic)\n",
    "print(result_logistic[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['prediction'] = result_logistic[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_result_logisticreg = test[['cust_id','prediction']]\n",
    "export_result_logisticreg.to_csv(r\"C:\\Users\\bajpa\\Desktop\\IESEG\\Stastical and Machine Learning Approaches\\Individual Project\\kaggle4.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Boosted Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#0.61277 for total score kaggle 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier()"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boostedTree.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_boostedTree=boostedTree.predict_proba(test_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.8977669  0.1022331 ]\n",
      " [0.95543891 0.04456109]\n",
      " [0.94846415 0.05153585]\n",
      " ...\n",
      " [0.91165384 0.08834616]\n",
      " [0.94223132 0.05776868]\n",
      " [0.95694303 0.04305697]]\n"
     ]
    }
   ],
   "source": [
    "print(prediction_boostedTree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       0.102233\n",
      "1       0.044561\n",
      "2       0.051536\n",
      "3       0.114491\n",
      "4       0.072607\n",
      "          ...   \n",
      "9995    0.091968\n",
      "9996    0.028753\n",
      "9997    0.088346\n",
      "9998    0.057769\n",
      "9999    0.043057\n",
      "Name: 1, Length: 10000, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "result_boostedTree = pd.DataFrame(prediction_boostedTree)\n",
    "print(result_boostedTree[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['prediction'] = result_boostedTree[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_result_boostedTree = test[['cust_id','prediction']]\n",
    "export_result_boostedTree.to_csv(r\"C:\\Users\\bajpa\\Desktop\\IESEG\\Stastical and Machine Learning Approaches\\Individual Project\\kaggle3.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#worst score... 0.49976 kaggle 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "svclassifier = SVC(kernel='linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(kernel='linear', probability=True)"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear')\n",
    "svclassifier.probability = True\n",
    "svclassifier.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_svm=svclassifier.predict_proba(test_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.90659015 0.09340985]\n",
      " [0.90197247 0.09802753]\n",
      " [0.93590126 0.06409874]\n",
      " ...\n",
      " [0.91292222 0.08707778]\n",
      " [0.88682783 0.11317217]\n",
      " [0.92290393 0.07709607]]\n"
     ]
    }
   ],
   "source": [
    "print(prediction_svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       0.093410\n",
      "1       0.098028\n",
      "2       0.064099\n",
      "3       0.063769\n",
      "4       0.084125\n",
      "          ...   \n",
      "9995    0.068830\n",
      "9996    0.081103\n",
      "9997    0.087078\n",
      "9998    0.113172\n",
      "9999    0.077096\n",
      "Name: 1, Length: 10000, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "result_svm = pd.DataFrame(prediction_svm)\n",
    "print(result_svm[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['prediction'] = result_svm[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_result_svm = test[['cust_id','prediction']]\n",
    "export_result_svm.to_csv(r\"C:\\Users\\bajpa\\Desktop\\IESEG\\Stastical and Machine Learning Approaches\\Individual Project\\kaggle2.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0.58385 is the score kaggle 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction=gnb.predict(test_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictionproba = gnb.predict_proba(test_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.72057035 0.27942965]\n",
      " [0.96567739 0.03432261]\n",
      " [0.14775198 0.85224802]\n",
      " ...\n",
      " [0.9780142  0.0219858 ]\n",
      " [0.96505571 0.03494429]\n",
      " [0.93943088 0.06056912]]\n"
     ]
    }
   ],
   "source": [
    "print(predictionproba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       0.279430\n",
      "1       0.034323\n",
      "2       0.852248\n",
      "3       0.381420\n",
      "4       0.016880\n",
      "          ...   \n",
      "9995    0.366915\n",
      "9996    0.000221\n",
      "9997    0.021986\n",
      "9998    0.034944\n",
      "9999    0.060569\n",
      "Name: 1, Length: 10000, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "result = pd.DataFrame(predictionproba)\n",
    "print(result[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['prediction'] = result[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_result = test[['cust_id','prediction']]\n",
    "export_result.to_csv(r\"C:\\Users\\bajpa\\Desktop\\IESEG\\Stastical and Machine Learning Approaches\\Individual Project\\kaggle1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\"tree\"         :tree,\n",
    "          \"logistic\"     :logistic,\n",
    "          \"randomForest\" :randomForest,\n",
    "          \"boostedTree\"  :boostedTree,\n",
    "          \"svm\"          :svm,\n",
    "          \"neuralNet\"    :neuralNet,\n",
    "          \"neighbors\"    :neighbors\n",
    "         } "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tree has been trained successfully\n",
      "logistic has been trained successfully\n",
      "randomForest has been trained successfully\n",
      "boostedTree has been trained successfully\n",
      "svm has been trained successfully\n",
      "neuralNet has been trained successfully\n",
      "neighbors has been trained successfully\n"
     ]
    }
   ],
   "source": [
    "for model in models:\n",
    "    models[model].fit(x_train,y_train)\n",
    "    print(f\"{model} has been trained successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "performances_train = {}\n",
    "\n",
    "for model in models:\n",
    "    predictions   = models[model].predict(x_train)\n",
    "    probabilities = DataFrame(models[model].predict_proba(x_train))[1]\n",
    "    accuracy      = accuracy_score(y_train,predictions)\n",
    "    auc           = roc_auc_score(array(y_train),array(probabilities))\n",
    "    \n",
    "    performances_train[model] = {\"Accuracy\":accuracy,\"AUC\":auc,\"Probabilities\":probabilities}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tree</th>\n",
       "      <th>logistic</th>\n",
       "      <th>randomForest</th>\n",
       "      <th>boostedTree</th>\n",
       "      <th>svm</th>\n",
       "      <th>neuralNet</th>\n",
       "      <th>neighbors</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Accuracy</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.958833</td>\n",
       "      <td>0.999833</td>\n",
       "      <td>0.929667</td>\n",
       "      <td>0.9265</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.929333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AUC</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.996891</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.957889</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.911736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Probabilities</th>\n",
       "      <td>0       0.0\n",
       "1       0.0\n",
       "2       0.0\n",
       "3       0....</td>\n",
       "      <td>0       0.023321\n",
       "1       0.085306\n",
       "2       0.06...</td>\n",
       "      <td>0       0.05\n",
       "1       0.04\n",
       "2       0.03\n",
       "3      ...</td>\n",
       "      <td>0       0.031389\n",
       "1       0.094468\n",
       "2       0.07...</td>\n",
       "      <td>0       0.060821\n",
       "1       0.067713\n",
       "2       0.06...</td>\n",
       "      <td>0       3.277046e-04\n",
       "1       4.984098e-04\n",
       "2   ...</td>\n",
       "      <td>0       0.0\n",
       "1       0.0\n",
       "2       0.0\n",
       "3       0....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                            tree  \\\n",
       "Accuracy                                                     1.0   \n",
       "AUC                                                          1.0   \n",
       "Probabilities  0       0.0\n",
       "1       0.0\n",
       "2       0.0\n",
       "3       0....   \n",
       "\n",
       "                                                        logistic  \\\n",
       "Accuracy                                                0.958833   \n",
       "AUC                                                     0.996891   \n",
       "Probabilities  0       0.023321\n",
       "1       0.085306\n",
       "2       0.06...   \n",
       "\n",
       "                                                    randomForest  \\\n",
       "Accuracy                                                0.999833   \n",
       "AUC                                                          1.0   \n",
       "Probabilities  0       0.05\n",
       "1       0.04\n",
       "2       0.03\n",
       "3      ...   \n",
       "\n",
       "                                                     boostedTree  \\\n",
       "Accuracy                                                0.929667   \n",
       "AUC                                                     0.957889   \n",
       "Probabilities  0       0.031389\n",
       "1       0.094468\n",
       "2       0.07...   \n",
       "\n",
       "                                                             svm  \\\n",
       "Accuracy                                                  0.9265   \n",
       "AUC                                                          1.0   \n",
       "Probabilities  0       0.060821\n",
       "1       0.067713\n",
       "2       0.06...   \n",
       "\n",
       "                                                       neuralNet  \\\n",
       "Accuracy                                                     1.0   \n",
       "AUC                                                          1.0   \n",
       "Probabilities  0       3.277046e-04\n",
       "1       4.984098e-04\n",
       "2   ...   \n",
       "\n",
       "                                                       neighbors  \n",
       "Accuracy                                                0.929333  \n",
       "AUC                                                     0.911736  \n",
       "Probabilities  0       0.0\n",
       "1       0.0\n",
       "2       0.0\n",
       "3       0....  "
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# performances on the training set\n",
    "DataFrame(performances_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "performances_test = {}\n",
    "\n",
    "for model in models:\n",
    "    predictions_test   = models[model].predict(x_test)\n",
    "    probabilities_test = DataFrame(models[model].predict_proba(x_test))[1]\n",
    "    accuracy_test      = accuracy_score(y_test,predictions_test)\n",
    "    auc_test           = roc_auc_score(array(y_test),array(probabilities_test))\n",
    "    \n",
    "    performances_test[model] = {\"Probabilities\":probabilities_test,\"AUC\":auc}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tree</th>\n",
       "      <th>logistic</th>\n",
       "      <th>randomForest</th>\n",
       "      <th>boostedTree</th>\n",
       "      <th>svm</th>\n",
       "      <th>neuralNet</th>\n",
       "      <th>neighbors</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Probabilities</th>\n",
       "      <td>0       0.0\n",
       "1       0.0\n",
       "2       0.0\n",
       "3       0....</td>\n",
       "      <td>0       0.012720\n",
       "1       0.011290\n",
       "2       0.22...</td>\n",
       "      <td>0       0.01\n",
       "1       0.01\n",
       "2       0.12\n",
       "3      ...</td>\n",
       "      <td>0       0.055930\n",
       "1       0.053589\n",
       "2       0.04...</td>\n",
       "      <td>0       0.037654\n",
       "1       0.041775\n",
       "2       0.17...</td>\n",
       "      <td>0       2.467119e-04\n",
       "1       1.587239e-05\n",
       "2   ...</td>\n",
       "      <td>0       0.0\n",
       "1       0.0\n",
       "2       0.0\n",
       "3       0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AUC</th>\n",
       "      <td>0.911736</td>\n",
       "      <td>0.911736</td>\n",
       "      <td>0.911736</td>\n",
       "      <td>0.911736</td>\n",
       "      <td>0.911736</td>\n",
       "      <td>0.911736</td>\n",
       "      <td>0.911736</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                            tree  \\\n",
       "Probabilities  0       0.0\n",
       "1       0.0\n",
       "2       0.0\n",
       "3       0....   \n",
       "AUC                                                     0.911736   \n",
       "\n",
       "                                                        logistic  \\\n",
       "Probabilities  0       0.012720\n",
       "1       0.011290\n",
       "2       0.22...   \n",
       "AUC                                                     0.911736   \n",
       "\n",
       "                                                    randomForest  \\\n",
       "Probabilities  0       0.01\n",
       "1       0.01\n",
       "2       0.12\n",
       "3      ...   \n",
       "AUC                                                     0.911736   \n",
       "\n",
       "                                                     boostedTree  \\\n",
       "Probabilities  0       0.055930\n",
       "1       0.053589\n",
       "2       0.04...   \n",
       "AUC                                                     0.911736   \n",
       "\n",
       "                                                             svm  \\\n",
       "Probabilities  0       0.037654\n",
       "1       0.041775\n",
       "2       0.17...   \n",
       "AUC                                                     0.911736   \n",
       "\n",
       "                                                       neuralNet  \\\n",
       "Probabilities  0       2.467119e-04\n",
       "1       1.587239e-05\n",
       "2   ...   \n",
       "AUC                                                     0.911736   \n",
       "\n",
       "                                                       neighbors  \n",
       "Probabilities  0       0.0\n",
       "1       0.0\n",
       "2       0.0\n",
       "3       0....  \n",
       "AUC                                                     0.911736  "
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# performances on the test set\n",
    "DataFrame(performances_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2656    0\n",
       "445     0\n",
       "9505    0\n",
       "332     0\n",
       "4168    0\n",
       "       ..\n",
       "8018    0\n",
       "6463    0\n",
       "2883    0\n",
       "7895    0\n",
       "620     0\n",
       "Name: churn, Length: 2000, dtype: int64"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Other useful references\n",
    "\n",
    "1. Dynamic Classifier Selection Ensembles in Python. Link: https://machinelearningmastery.com/dynamic-classifier-selection-in-python/\n",
    "2. How to Develop a Feature Selection Subspace Ensemble in Python. Link: https://machinelearningmastery.com/feature-selection-subspace-ensemble-in-python/\n",
    "3. How to Choose a Feature Selection Method For Machine Learning. Link: https://machinelearningmastery.com/feature-selection-with-real-and-categorical-data/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
